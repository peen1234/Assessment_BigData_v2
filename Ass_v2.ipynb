{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peen1234/Assessment_BigData_v2/blob/main/Ass_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXL7yTc3xc18"
      },
      "source": [
        "## BUSN9165 -- Big Data Analytics and Visualisation <br> Seminar 6 <br> Week 30 (w/c 21 Feb 2022)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiFBtwv1xc1_"
      },
      "source": [
        "Author: Zhen Zhu <br> Email: z.zhu@kent.ac.uk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-qhDHTSxc2I"
      },
      "source": [
        "### <font color=red>This notebook needs to be run on Colab!!!</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcIqWf6Xxc2A"
      },
      "source": [
        "## 0. Exercises solutions for Week 29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb4bdMAkxc2I"
      },
      "outputs": [],
      "source": [
        "# Download Java and Spark\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TLjlRD0xc2I"
      },
      "outputs": [],
      "source": [
        "# Set up the paths\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itU0YfhKxc2J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "f3bbba29-db27-4939-cb87-fa01e4906d8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://f8fa7329a7d7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fef5c891350>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# Create a Spark session\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True) # Property used to format output tables better\n",
        "spark.conf.set(\"spark.sql.caseSensitive\", True) # Avoid error \"Found duplicate column(s) in the data schema\"\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>Exercise 5.0</font>"
      ],
      "metadata": {
        "id": "VPm4naWk3CWL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>Upload the file \"titanic_train.csv\" to the runtime</font>"
      ],
      "metadata": {
        "id": "YGBhfOUM3Ol4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>Use PySpark dataframe operations to get information for all male passengers with age 50 and above</font>"
      ],
      "metadata": {
        "id": "JSIe76nm3CWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First load the data (be sure it is uploaded in the runtime)\n",
        "titanic_train = spark.read.csv('titanic_train.csv', header = True, inferSchema=True)\n",
        "\n",
        "# Use multiple conditions to get the information required\n",
        "titanic_train.filter((titanic_train[\"Age\"] >= 50) &\n",
        "                     (titanic_train[\"Sex\"] == 'male')\n",
        "                     ).show()"
      ],
      "metadata": {
        "id": "SqXVJF7B3mU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf14b838-4d13-47bd-c047-66bf7d2810c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+--------+------+--------------------+----+----+-----+-----+-----------+-------+-----+--------+\n",
            "|PassengerId|Survived|Pclass|                Name| Sex| Age|SibSp|Parch|     Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+--------+------+--------------------+----+----+-----+-----+-----------+-------+-----+--------+\n",
            "|          7|       0|     1|McCarthy, Mr. Tim...|male|54.0|    0|    0|      17463|51.8625|  E46|       S|\n",
            "|         34|       0|     2|Wheadon, Mr. Edwa...|male|66.0|    0|    0| C.A. 24579|   10.5| null|       S|\n",
            "|         55|       0|     1|Ostby, Mr. Engelh...|male|65.0|    0|    1|     113509|61.9792|  B30|       C|\n",
            "|         95|       0|     3|   Coxon, Mr. Daniel|male|59.0|    0|    0|     364500|   7.25| null|       S|\n",
            "|         97|       0|     1|Goldschmidt, Mr. ...|male|71.0|    0|    0|   PC 17754|34.6542|   A5|       C|\n",
            "|        117|       0|     3|Connors, Mr. Patrick|male|70.5|    0|    0|     370369|   7.75| null|       Q|\n",
            "|        125|       0|     1|White, Mr. Perciv...|male|54.0|    0|    1|      35281|77.2875|  D26|       S|\n",
            "|        151|       0|     2|Bateman, Rev. Rob...|male|51.0|    0|    0|S.O.P. 1166| 12.525| null|       S|\n",
            "|        153|       0|     3|    Meo, Mr. Alfonzo|male|55.5|    0|    0| A.5. 11206|   8.05| null|       S|\n",
            "|        156|       0|     1|Williams, Mr. Cha...|male|51.0|    0|    1|   PC 17597|61.3792| null|       C|\n",
            "|        171|       0|     1|Van der hoef, Mr....|male|61.0|    0|    0|     111240|   33.5|  B19|       S|\n",
            "|        175|       0|     1|Smith, Mr. James ...|male|56.0|    0|    0|      17764|30.6958|   A7|       C|\n",
            "|        223|       0|     3|Green, Mr. George...|male|51.0|    0|    0|      21440|   8.05| null|       S|\n",
            "|        233|       0|     2|Sjostedt, Mr. Ern...|male|59.0|    0|    0|     237442|   13.5| null|       S|\n",
            "|        250|       0|     2|Carter, Rev. Erne...|male|54.0|    1|    0|     244252|   26.0| null|       S|\n",
            "|        253|       0|     1|Stead, Mr. Willia...|male|62.0|    0|    0|     113514|  26.55|  C87|       S|\n",
            "|        263|       0|     1|   Taussig, Mr. Emil|male|52.0|    1|    1|     110413|  79.65|  E67|       S|\n",
            "|        281|       0|     3|    Duane, Mr. Frank|male|65.0|    0|    0|     336439|   7.75| null|       Q|\n",
            "|        318|       0|     2|Moraweck, Dr. Ernest|male|54.0|    0|    0|      29011|   14.0| null|       S|\n",
            "|        327|       0|     3|Nysveen, Mr. Joha...|male|61.0|    0|    0|     345364| 6.2375| null|       S|\n",
            "+-----------+--------+------+--------------------+----+----+-----+-----+-----------+-------+-----+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>Exercise 5.1</font>"
      ],
      "metadata": {
        "id": "KX52dyRv3CWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>Use SQL statements to get information for the oldest passenger in first class</font>"
      ],
      "metadata": {
        "id": "fJpwYQ0k3CWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SQL temp view from the dataframe\n",
        "titanic_train.createOrReplaceTempView(\"titanicTable\")\n",
        "\n",
        "# Use SQL query to retrieve the information\n",
        "spark.sql(\"SELECT * FROM titanicTable WHERE Pclass = 1 ORDER BY Age DESC\")"
      ],
      "metadata": {
        "id": "FYKPu0Y80cod",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "c74cafdb-ea75-4549-c541-7c1770f654a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>PassengerId</th><th>Survived</th><th>Pclass</th><th>Name</th><th>Sex</th><th>Age</th><th>SibSp</th><th>Parch</th><th>Ticket</th><th>Fare</th><th>Cabin</th><th>Embarked</th></tr>\n",
              "<tr><td>631</td><td>1</td><td>1</td><td>Barkworth, Mr. Al...</td><td>male</td><td>80.0</td><td>0</td><td>0</td><td>27042</td><td>30.0</td><td>A23</td><td>S</td></tr>\n",
              "<tr><td>494</td><td>0</td><td>1</td><td>Artagaveytia, Mr....</td><td>male</td><td>71.0</td><td>0</td><td>0</td><td>PC 17609</td><td>49.5042</td><td>null</td><td>C</td></tr>\n",
              "<tr><td>97</td><td>0</td><td>1</td><td>Goldschmidt, Mr. ...</td><td>male</td><td>71.0</td><td>0</td><td>0</td><td>PC 17754</td><td>34.6542</td><td>A5</td><td>C</td></tr>\n",
              "<tr><td>746</td><td>0</td><td>1</td><td>Crosby, Capt. Edw...</td><td>male</td><td>70.0</td><td>1</td><td>1</td><td>WE/P 5735</td><td>71.0</td><td>B22</td><td>S</td></tr>\n",
              "<tr><td>55</td><td>0</td><td>1</td><td>Ostby, Mr. Engelh...</td><td>male</td><td>65.0</td><td>0</td><td>1</td><td>113509</td><td>61.9792</td><td>B30</td><td>C</td></tr>\n",
              "<tr><td>457</td><td>0</td><td>1</td><td>Millet, Mr. Franc...</td><td>male</td><td>65.0</td><td>0</td><td>0</td><td>13509</td><td>26.55</td><td>E38</td><td>S</td></tr>\n",
              "<tr><td>439</td><td>0</td><td>1</td><td>Fortune, Mr. Mark</td><td>male</td><td>64.0</td><td>1</td><td>4</td><td>19950</td><td>263.0</td><td>C23 C25 C27</td><td>S</td></tr>\n",
              "<tr><td>546</td><td>0</td><td>1</td><td>Nicholson, Mr. Ar...</td><td>male</td><td>64.0</td><td>0</td><td>0</td><td>693</td><td>26.0</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>276</td><td>1</td><td>1</td><td>Andrews, Miss. Ko...</td><td>female</td><td>63.0</td><td>1</td><td>0</td><td>13502</td><td>77.9583</td><td>D7</td><td>S</td></tr>\n",
              "<tr><td>830</td><td>1</td><td>1</td><td>Stone, Mrs. Georg...</td><td>female</td><td>62.0</td><td>0</td><td>0</td><td>113572</td><td>80.0</td><td>B28</td><td>null</td></tr>\n",
              "<tr><td>556</td><td>0</td><td>1</td><td>Wright, Mr. George</td><td>male</td><td>62.0</td><td>0</td><td>0</td><td>113807</td><td>26.55</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>253</td><td>0</td><td>1</td><td>Stead, Mr. Willia...</td><td>male</td><td>62.0</td><td>0</td><td>0</td><td>113514</td><td>26.55</td><td>C87</td><td>S</td></tr>\n",
              "<tr><td>171</td><td>0</td><td>1</td><td>Van der hoef, Mr....</td><td>male</td><td>61.0</td><td>0</td><td>0</td><td>111240</td><td>33.5</td><td>B19</td><td>S</td></tr>\n",
              "<tr><td>626</td><td>0</td><td>1</td><td>Sutton, Mr. Frede...</td><td>male</td><td>61.0</td><td>0</td><td>0</td><td>36963</td><td>32.3208</td><td>D50</td><td>S</td></tr>\n",
              "<tr><td>367</td><td>1</td><td>1</td><td>Warren, Mrs. Fran...</td><td>female</td><td>60.0</td><td>1</td><td>0</td><td>110813</td><td>75.25</td><td>D37</td><td>C</td></tr>\n",
              "<tr><td>588</td><td>1</td><td>1</td><td>Frolicher-Stehli,...</td><td>male</td><td>60.0</td><td>1</td><td>1</td><td>13567</td><td>79.2</td><td>B41</td><td>C</td></tr>\n",
              "<tr><td>695</td><td>0</td><td>1</td><td>Weir, Col. John</td><td>male</td><td>60.0</td><td>0</td><td>0</td><td>113800</td><td>26.55</td><td>null</td><td>S</td></tr>\n",
              "<tr><td>269</td><td>1</td><td>1</td><td>Graham, Mrs. Will...</td><td>female</td><td>58.0</td><td>0</td><td>1</td><td>PC 17582</td><td>153.4625</td><td>C125</td><td>S</td></tr>\n",
              "<tr><td>196</td><td>1</td><td>1</td><td>Lurette, Miss. Elise</td><td>female</td><td>58.0</td><td>0</td><td>0</td><td>PC 17569</td><td>146.5208</td><td>B80</td><td>C</td></tr>\n",
              "<tr><td>488</td><td>0</td><td>1</td><td>Kent, Mr. Edward ...</td><td>male</td><td>58.0</td><td>0</td><td>0</td><td>11771</td><td>29.7</td><td>B37</td><td>C</td></tr>\n",
              "</table>\n",
              "only showing top 20 rows\n"
            ],
            "text/plain": [
              "+-----------+--------+------+--------------------+------+----+-----+-----+---------+--------+-----------+--------+\n",
              "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|   Ticket|    Fare|      Cabin|Embarked|\n",
              "+-----------+--------+------+--------------------+------+----+-----+-----+---------+--------+-----------+--------+\n",
              "|        631|       1|     1|Barkworth, Mr. Al...|  male|80.0|    0|    0|    27042|    30.0|        A23|       S|\n",
              "|        494|       0|     1|Artagaveytia, Mr....|  male|71.0|    0|    0| PC 17609| 49.5042|       null|       C|\n",
              "|         97|       0|     1|Goldschmidt, Mr. ...|  male|71.0|    0|    0| PC 17754| 34.6542|         A5|       C|\n",
              "|        746|       0|     1|Crosby, Capt. Edw...|  male|70.0|    1|    1|WE/P 5735|    71.0|        B22|       S|\n",
              "|         55|       0|     1|Ostby, Mr. Engelh...|  male|65.0|    0|    1|   113509| 61.9792|        B30|       C|\n",
              "|        457|       0|     1|Millet, Mr. Franc...|  male|65.0|    0|    0|    13509|   26.55|        E38|       S|\n",
              "|        439|       0|     1|   Fortune, Mr. Mark|  male|64.0|    1|    4|    19950|   263.0|C23 C25 C27|       S|\n",
              "|        546|       0|     1|Nicholson, Mr. Ar...|  male|64.0|    0|    0|      693|    26.0|       null|       S|\n",
              "|        276|       1|     1|Andrews, Miss. Ko...|female|63.0|    1|    0|    13502| 77.9583|         D7|       S|\n",
              "|        830|       1|     1|Stone, Mrs. Georg...|female|62.0|    0|    0|   113572|    80.0|        B28|    null|\n",
              "|        556|       0|     1|  Wright, Mr. George|  male|62.0|    0|    0|   113807|   26.55|       null|       S|\n",
              "|        253|       0|     1|Stead, Mr. Willia...|  male|62.0|    0|    0|   113514|   26.55|        C87|       S|\n",
              "|        171|       0|     1|Van der hoef, Mr....|  male|61.0|    0|    0|   111240|    33.5|        B19|       S|\n",
              "|        626|       0|     1|Sutton, Mr. Frede...|  male|61.0|    0|    0|    36963| 32.3208|        D50|       S|\n",
              "|        367|       1|     1|Warren, Mrs. Fran...|female|60.0|    1|    0|   110813|   75.25|        D37|       C|\n",
              "|        588|       1|     1|Frolicher-Stehli,...|  male|60.0|    1|    1|    13567|    79.2|        B41|       C|\n",
              "|        695|       0|     1|     Weir, Col. John|  male|60.0|    0|    0|   113800|   26.55|       null|       S|\n",
              "|        269|       1|     1|Graham, Mrs. Will...|female|58.0|    0|    1| PC 17582|153.4625|       C125|       S|\n",
              "|        196|       1|     1|Lurette, Miss. Elise|female|58.0|    0|    0| PC 17569|146.5208|        B80|       C|\n",
              "|        488|       0|     1|Kent, Mr. Edward ...|  male|58.0|    0|    0|    11771|    29.7|        B37|       C|\n",
              "+-----------+--------+------+--------------------+------+----+-----+-----+---------+--------+-----------+--------+\n",
              "only showing top 20 rows"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>Exercise 5.2</font>"
      ],
      "metadata": {
        "id": "ebs0OZSb7Kse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>Upload the file \"cruise_ship_info.csv\" to the runtime</font>"
      ],
      "metadata": {
        "id": "oijj-kPJ7j8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>Use Spark MLlib to build a linear regression model to predict the number of crew members (i.e., the \"crew\" column)</font>"
      ],
      "metadata": {
        "id": "tB57K7WF7Kse"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First load the data (be sure it is uploaded in the runtime)\n",
        "cruise = spark.read.csv('cruise_ship_info.csv', header = True, inferSchema=True)\n",
        "\n",
        "# Take a look\n",
        "cruise.show(5)"
      ],
      "metadata": {
        "id": "ee7lADJ67Kse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00919b1b-bbae-450d-d0d4-da796d450fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|\n",
            "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|\n",
            "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|\n",
            "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy variable for Cruise_line\n",
        "# Note that we also use OneHotEncoder this time\n",
        "from pyspark.ml.feature import OneHotEncoder,StringIndexer\n",
        "\n",
        "# Create indexer for Cruise_line\n",
        "stringIndexer = StringIndexer(inputCol='Cruise_line', outputCol='lineIndex')\n",
        "\n",
        "# Update the dataframe\n",
        "cruise = stringIndexer.fit(cruise).transform(cruise)\n",
        "\n",
        "# Create labels/categories for Cruise_line\n",
        "encoder = OneHotEncoder(inputCol=\"lineIndex\",outputCol=\"lineCat\")\n",
        "\n",
        "# Update the dataframe\n",
        "cruise = encoder.fit(cruise).transform(cruise)\n",
        "\n",
        "# Take another look\n",
        "cruise.show(5)"
      ],
      "metadata": {
        "id": "kDcwUcv0Mtho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "251741f3-3ca6-47b3-9976-4f769f3a6ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+---------+---------------+\n",
            "|  Ship_name|Cruise_line|Age|           Tonnage|passengers|length|cabins|passenger_density|crew|lineIndex|        lineCat|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+---------+---------------+\n",
            "|    Journey|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|     16.0|(19,[16],[1.0])|\n",
            "|      Quest|    Azamara|  6|30.276999999999997|      6.94|  5.94|  3.55|            42.64|3.55|     16.0|(19,[16],[1.0])|\n",
            "|Celebration|   Carnival| 26|            47.262|     14.86|  7.22|  7.43|             31.8| 6.7|      1.0| (19,[1],[1.0])|\n",
            "|   Conquest|   Carnival| 11|             110.0|     29.74|  9.53| 14.88|            36.99|19.1|      1.0| (19,[1],[1.0])|\n",
            "|    Destiny|   Carnival| 17|           101.353|     26.42|  8.92| 13.21|            38.36|10.0|      1.0| (19,[1],[1.0])|\n",
            "+-----------+-----------+---+------------------+----------+------+------+-----------------+----+---------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare feature vector\n",
        "\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "feature = VectorAssembler(inputCols=['Age',\n",
        "                                     'Tonnage',\n",
        "                                     'passengers',\n",
        "                                     'length',\n",
        "                                     'cabins',\n",
        "                                     'passenger_density',\n",
        "                                     'lineCat'],\n",
        "                          outputCol='features')\n",
        "\n",
        "feature_vector = feature.transform(cruise)\n",
        "feature_vector.select('features','crew').show(5)"
      ],
      "metadata": {
        "id": "9vFXoPmnOc4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b44c05-1d74-405a-99d8-4c3dba3b3763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----+\n",
            "|            features|crew|\n",
            "+--------------------+----+\n",
            "|(25,[0,1,2,3,4,5,...|3.55|\n",
            "|(25,[0,1,2,3,4,5,...|3.55|\n",
            "|(25,[0,1,2,3,4,5,...| 6.7|\n",
            "|(25,[0,1,2,3,4,5,...|19.1|\n",
            "|(25,[0,1,2,3,4,5,...|10.0|\n",
            "+--------------------+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a split\n",
        "\n",
        "(training, test) = feature_vector.randomSplit([0.8, 0.2],seed = 9165)"
      ],
      "metadata": {
        "id": "IaZQYDsOI1CE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use linear regression\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "lr = LinearRegression(labelCol=\"crew\",featuresCol=\"features\")\n",
        "\n",
        "# Set up the model\n",
        "lrModel = lr.fit(training)\n",
        "lr_prediction=lrModel.transform(test)\n",
        "lr_prediction.select(\"prediction\",\"crew\",\"features\").show(50)\n",
        "evaluator = lrModel.evaluate(test)"
      ],
      "metadata": {
        "id": "VlKizuN7Olpp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41c13202-fa5f-4bd8-a8f8-bf40f1447644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----+--------------------+\n",
            "|        prediction|crew|            features|\n",
            "+------------------+----+--------------------+\n",
            "| 9.328889393474242| 9.2|(25,[0,1,2,3,4,5,...|\n",
            "| 8.649011577410096| 8.5|(25,[0,1,2,3,4,5,...|\n",
            "|12.094292463839974|19.1|(25,[0,1,2,3,4,5,...|\n",
            "| 10.03067056358039|11.0|(25,[0,1,2,3,4,5,...|\n",
            "|  9.19152129172058| 9.0|(25,[0,1,2,3,4,5,...|\n",
            "|   8.7884253665257| 9.2|(25,[0,1,2,3,4,5,...|\n",
            "|11.387556286555686|11.5|(25,[0,1,2,3,4,5,...|\n",
            "|13.406293612352925|13.6|(25,[0,1,2,3,4,5,...|\n",
            "| 8.728125747138513| 9.2|(25,[0,1,2,3,4,5,...|\n",
            "| 9.390530467691573| 9.0|(25,[0,1,2,3,4,5,...|\n",
            "|10.023619413158695|11.0|(25,[0,1,2,3,4,5,...|\n",
            "|  6.99017923147293| 7.0|(25,[0,1,2,3,4,5,...|\n",
            "| 5.436389308378022|5.57|(25,[0,1,2,3,4,5,...|\n",
            "| 9.318767958317476| 9.2|(25,[0,1,2,3,4,5,...|\n",
            "|  9.79074915741353|9.99|(25,[0,1,2,3,4,5,...|\n",
            "| 9.635579930888643|10.3|(25,[0,1,2,3,4,5,...|\n",
            "| 8.268518565852947|7.94|(25,[0,1,2,3,4,5,...|\n",
            "|  7.36821318300161| 7.5|(25,[0,1,2,3,4,5,...|\n",
            "| 3.549999999999999|3.55|(25,[0,1,2,3,4,5,...|\n",
            "| 8.590589847852694| 9.0|(25,[0,1,2,3,4,5,...|\n",
            "| 5.982999212415893|6.36|(25,[0,1,2,3,4,5,...|\n",
            "| 8.077181519898122|8.08|(25,[0,1,2,3,4,5,...|\n",
            "|  8.74978152941128|13.0|(25,[0,1,2,3,4,5,...|\n",
            "|11.191522821115072|12.0|(25,[0,1,2,3,4,5,...|\n",
            "| 9.780770008428497|9.99|(25,[0,1,2,3,4,5,...|\n",
            "|2.2682302831387586| 1.8|(25,[0,1,2,3,4,5,...|\n",
            "|3.4406060313984312|3.73|(25,[0,1,2,3,4,5,...|\n",
            "| 5.411754112888251|5.88|(25,[0,1,2,3,4,5,...|\n",
            "| 6.222283620271418|5.61|(25,[0,1,2,3,4,5,...|\n",
            "|2.7861885171702516|2.87|(25,[0,1,2,3,4,5,...|\n",
            "| 7.293039182270543|6.14|(25,[0,1,2,3,4,5,...|\n",
            "+------------------+----+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Report R-squared as model evaluation\n",
        "\n",
        "print('R Squared of this linear regression model is %g'%(evaluator.r2))"
      ],
      "metadata": {
        "id": "VSMxmt0nOsrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88fa5c7-bc90-410b-ed8c-a7de98683b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R Squared of this linear regression model is 0.797906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gm9hlRBnxc2H"
      },
      "source": [
        "## 1. PySpark MLlib sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Again make sure 'Airline-Sentiment.csv' is in the runtime. \n",
        "\n",
        "# Load the csv into a dataframe\n",
        "# This time we add \"inferSchema=True\" so that \"retweet_count\" is recognised as integer type\n",
        "myData = spark.read.csv(\"Airline-Sentiment.csv\",header=True,encoding='latin1',escape=\"\\\"\",multiLine=True,inferSchema=True)\n",
        "myData.show(5)"
      ],
      "metadata": {
        "id": "-Q0VGRN_Yz_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c03c4e4-b779-41b2-98aa-6665bba99ac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+--------------+-------------+--------------------+-----------+-------------+--------------+--------------------+\n",
            "|airline_sentiment|       airline|retweet_count|                text|tweet_coord|tweet_created|tweet_location|       user_timezone|\n",
            "+-----------------+--------------+-------------+--------------------+-----------+-------------+--------------+--------------------+\n",
            "|          neutral|Virgin America|            0|@VirginAmerica Wh...|       null|2/24/15 11:35|          null|Eastern Time (US ...|\n",
            "|         positive|Virgin America|            0|@VirginAmerica pl...|       null|2/24/15 11:15|          null|Pacific Time (US ...|\n",
            "|          neutral|Virgin America|            0|@VirginAmerica I ...|       null|2/24/15 11:15|     Lets Play|Central Time (US ...|\n",
            "|         negative|Virgin America|            0|@VirginAmerica it...|       null|2/24/15 11:15|          null|Pacific Time (US ...|\n",
            "|         negative|Virgin America|            0|@VirginAmerica an...|       null|2/24/15 11:14|          null|Pacific Time (US ...|\n",
            "+-----------------+--------------+-------------+--------------------+-----------+-------------+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# More operations are available from Spark's SQL functions\n",
        "from pyspark.sql import functions as f"
      ],
      "metadata": {
        "id": "2O6TwK2hP5wM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tidy up the text data\n",
        "\n",
        "myData = (myData\n",
        "          #Remove handles\n",
        "          .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \"@[\\w]*\", \"\"))\n",
        "          #Remove special characters\n",
        "          .withColumn(\"text\", f.regexp_replace(f.col(\"text\"), \"[^a-zA-Z']\", \" \"))\n",
        "          #Remove leading and trailing whitespaces\n",
        "          .withColumn(\"text\", f.trim(f.col(\"text\")))\n",
        "          #Restrict the length of the string\n",
        "          .filter(f.length(\"text\")>50)\n",
        "          )"
      ],
      "metadata": {
        "id": "MpYO_aQn2ATN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the positive ones\n",
        "myDataPos = myData.filter(\"airline_sentiment = 'positive'\")\n",
        "\n",
        "# Get the negative ones\n",
        "myDataNeg = myData.filter(\"airline_sentiment = 'negative'\")"
      ],
      "metadata": {
        "id": "DLTLUy8zpW7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sample from positive\n",
        "myDataPosSample = myDataPos.sample(fraction=1000/myDataPos.count(), seed=9165)\n",
        "\n",
        "# Get a random sample from negative\n",
        "myDataNegSample = myDataNeg.sample(fraction=1000/myDataNeg.count(), seed=9165)"
      ],
      "metadata": {
        "id": "62NGpxjZwFN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine into a single sample\n",
        "\n",
        "mySample = myDataPosSample.union(myDataNegSample)"
      ],
      "metadata": {
        "id": "GuDMRWp_wr5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look\n",
        "\n",
        "mySample.groupBy(\"airline_sentiment\").count()"
      ],
      "metadata": {
        "id": "c3hhQ6iu2WX_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "67e15282-426f-427c-ba47-accf3d8e05b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>airline_sentiment</th><th>count</th></tr>\n",
              "<tr><td>positive</td><td>971</td></tr>\n",
              "<tr><td>negative</td><td>960</td></tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "+-----------------+-----+\n",
              "|airline_sentiment|count|\n",
              "+-----------------+-----+\n",
              "|         positive|  971|\n",
              "|         negative|  960|\n",
              "+-----------------+-----+"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a split\n",
        "\n",
        "(training, test) = mySample.randomSplit([0.8, 0.2],seed = 9165)"
      ],
      "metadata": {
        "id": "W-IFRyVpgf8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the training\n",
        "\n",
        "training.groupBy(\"airline_sentiment\").count()"
      ],
      "metadata": {
        "id": "HFq5M9LwQ3st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the test\n",
        "\n",
        "test.groupBy(\"airline_sentiment\").count()"
      ],
      "metadata": {
        "id": "9XnEf4sNQ_0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.0 Bag-of-words approach"
      ],
      "metadata": {
        "id": "fte_268D1rlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use nickname feat for the subpackage\n",
        "import pyspark.ml.feature as feat\n",
        "\n",
        "# We need Pipeline to streamline the workflow\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Use logistic regression\n",
        "from pyspark.ml.classification import LogisticRegression"
      ],
      "metadata": {
        "id": "yJPvj6D-RGre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build up the pipeline/workflow\n",
        "\n",
        "# Split the tweets into words\n",
        "splitter = feat.RegexTokenizer(\n",
        "    inputCol='text'\n",
        "    , outputCol='text_split'\n",
        "    , pattern='\\s+'\n",
        ")\n",
        "\n",
        "# Remove stop words\n",
        "sw_remover = feat.StopWordsRemover(\n",
        "    inputCol=splitter.getOutputCol()\n",
        "    , outputCol='text_noSW'\n",
        ")\n",
        "\n",
        "# Count word frequency\n",
        "count_vec = feat.CountVectorizer(\n",
        "    inputCol=sw_remover.getOutputCol()\n",
        "    , outputCol='features'\n",
        "    , vocabSize=1000\n",
        ")\n",
        "\n",
        "# Prepare the target variable\n",
        "label_string = feat.StringIndexer(\n",
        "    inputCol = \"airline_sentiment\"\n",
        "    , outputCol = \"label\"\n",
        ")\n",
        "\n",
        "# Logistic regression model\n",
        "lr = LogisticRegression(\n",
        "    maxIter=100\n",
        ")\n",
        "\n",
        "\n",
        "# Finally set up the pipline\n",
        "sentiment_pipeline_bow = Pipeline(\n",
        "    stages=[\n",
        "            splitter\n",
        "            , sw_remover\n",
        "            , count_vec\n",
        "            , label_string\n",
        "            , lr\n",
        "            ]\n",
        ")"
      ],
      "metadata": {
        "id": "NZYheLEp2gh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import an evaluator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "lrModel = sentiment_pipeline_bow.fit(training)\n",
        "lr_prediction = lrModel.transform(test)\n",
        "lr_prediction.select(\"prediction\", \"airline_sentiment\", \"features\").show(50)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
      ],
      "metadata": {
        "id": "B3f1GKDE_vmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the accuracy\n",
        "\n",
        "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
        "print(\"Accuracy of this Logistic Regression model with bag-of-words approach is %g\"% (lr_accuracy))"
      ],
      "metadata": {
        "id": "kBYC0TxCkhD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a detailed look\n",
        "\n",
        "lr_prediction.show()"
      ],
      "metadata": {
        "id": "2w_WVCfs8KJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 TF-IDF approach"
      ],
      "metadata": {
        "id": "L2__smSt128Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# splitter\n",
        "\n",
        "splitter = feat.RegexTokenizer(inputCol='text', outputCol='text_split', pattern='\\s+')\n",
        "mySample = splitter.transform(mySample) "
      ],
      "metadata": {
        "id": "7VgkYWGLHhyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look\n",
        "\n",
        "mySample.show(5)"
      ],
      "metadata": {
        "id": "uRyWAmoOKBDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stop words remover\n",
        "\n",
        "sw_remover = feat.StopWordsRemover(inputCol='text_split', outputCol='text_noSW')\n",
        "mySample = sw_remover.transform(mySample) "
      ],
      "metadata": {
        "id": "zeI1Wc-zIjDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look\n",
        "\n",
        "mySample.show(5)"
      ],
      "metadata": {
        "id": "VMTJ_TlsKKkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count word frequency\n",
        "\n",
        "count_vec = feat.CountVectorizer(inputCol='text_noSW', outputCol='vector', vocabSize=1000)\n",
        "mySample = count_vec.fit(mySample).transform(mySample)"
      ],
      "metadata": {
        "id": "lW3iGDVwI-wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look\n",
        "\n",
        "mySample.show(5)"
      ],
      "metadata": {
        "id": "i9IlT-kLKeBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate IDF\n",
        "\n",
        "idf_cal = feat.IDF(inputCol='vector', outputCol='features')\n",
        "mySample = idf_cal.fit(mySample).transform(mySample)"
      ],
      "metadata": {
        "id": "vRL1E_zGVXn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look\n",
        "\n",
        "mySample.show(5)"
      ],
      "metadata": {
        "id": "dziSwhFrVzzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create indexer for sentiment\n",
        "\n",
        "label_string = feat.StringIndexer(inputCol='airline_sentiment', outputCol='label')\n",
        "mySample = label_string.fit(mySample).transform(mySample)"
      ],
      "metadata": {
        "id": "txPM-bptWOTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a split\n",
        "\n",
        "(training, test) = mySample.randomSplit([0.8, 0.2],seed = 9165)"
      ],
      "metadata": {
        "id": "dP3L0FdIWBTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use logistic regression\n",
        "lr = LogisticRegression(maxIter=100)\n",
        "\n",
        "# Set up the model\n",
        "lrModel = lr.fit(training)\n",
        "lr_prediction = lrModel.transform(test)\n",
        "lr_prediction.select(\"prediction\", \"airline_sentiment\", \"features\").show(50)\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
      ],
      "metadata": {
        "id": "CkWuX6RuWFI1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report the accuracy\n",
        "\n",
        "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
        "print(\"Accuracy of this Logistic Regression model with TF-IDF approach is %g\"% (lr_accuracy))"
      ],
      "metadata": {
        "id": "PCFWWLanXYpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYOn5N1Uxc2K"
      },
      "source": [
        "### <font color=blue>Exercise 6.0</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>Reorganise the steps in Section 1.1 with Pipeline.</font>"
      ],
      "metadata": {
        "id": "9lYv5ROzTNEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8TapMuh-TdKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color=blue>Exercise 6.1</font>"
      ],
      "metadata": {
        "id": "qPxAywaETKf3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r8uX5TQxc2N"
      },
      "source": [
        "### <font color=blue>Carry out a sentiment analysis with customer review text data from http://deepyeti.ucsd.edu/jianmo/amazon/index.html (hint: you may use 4/5 star rating as positive and 1/2 star rating as negative).</font>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Dgd7nsBmg5VD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "seminar6.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oijj-kPJ7j8q"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}